{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RVAE+NN_unfrozen.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "52UJvxJoCrIm",
        "outputId": "bf20e26e-c8fe-4469-ea8c-c9803a531779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/TheMrGhostman/Semi-supervised-Learning-with-VAE.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Semi-supervised-Learning-with-VAE'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 780 (delta 49), reused 78 (delta 34), pack-reused 678\u001b[K\n",
            "Receiving objects: 100% (780/780), 321.04 MiB | 33.43 MiB/s, done.\n",
            "Resolving deltas: 100% (280/280), done.\n",
            "Checking out files: 100% (496/496), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_nfGmeYACyh7",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.chdir(\"Semi-supervised-Learning-with-VAE/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lhXhvBCEC0HQ",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "from utils.inference import Trainer\n",
        "import utils.models as m\n",
        "import utils.datasets as d\n",
        "from utils.layers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uNnhk95IC9qr"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7hZ-4wacEnMw",
        "colab": {}
      },
      "source": [
        "X = np.vstack((np.load(\"data/sequenced_data_for_VAE_length-160_stride-10_pt1.npy\"),\n",
        "               np.load(\"data/sequenced_data_for_VAE_length-160_stride-10_pt2.npy\")))\n",
        "y = np.load(\"data/sequenced_data_for_VAE_length-160_stride-10_targets.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iumwd0J6EnO-",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.2, random_state=666)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3OEKyuTREnRd",
        "colab": {}
      },
      "source": [
        "scaler = RobustScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "boiu81hdEnUJ",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=666)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pLsIyVZUEnWP",
        "colab": {}
      },
      "source": [
        "train = d.H_alphaSequences(X_train, y_train)\n",
        "valid = d.H_alphaSequences(X_valid, y_valid)\n",
        "test = d.H_alphaSequences(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cGKRNP9tEnYg",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = train, batch_size=512, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset = valid, batch_size=512, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iAYOD1JeIXOg",
        "colab": {}
      },
      "source": [
        "VAE = torch.load(\"models_and_losses/DeepLSTM_VAE_NLL_440ep_hidden-128_lr-{1e-3, 1e-4}_bs-300.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2V0ophpnEK1E"
      },
      "source": [
        "# Freeze and Unfreeze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hB98xsO0IXwL",
        "colab": {}
      },
      "source": [
        "class RNN_Encoder_Classifier(nn.Module):\n",
        "    def __init__(self, model, clf):\n",
        "        super(RNN_Encoder_Classifier, self).__init__()\n",
        "        self.model = model\n",
        "        self.clf = clf\n",
        "        self.frozen_encoder = False\n",
        "\n",
        "    def freeze_encoder(self):\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.frozen_encoder = True\n",
        "        print(\"Encoder frozen.\")\n",
        "\n",
        "    def unfreeze_encoder(self):\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = True\n",
        "        self.frozen_encoder = False\n",
        "        print(\"Encoder unfrozen.\")\n",
        "    \n",
        "    def forward(self, X):\n",
        "        Z, mu, sigma = self.model.encoder(X)\n",
        "        return self.clf(Z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrfjcvTP03ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepLSTM_VAE(nn.Module):\n",
        "\tdef __init__(self, sequence_len, n_features, latent_dim, hidden_size=128, num_layers=2, batch_size=100, use_cuda=True):\n",
        "\t\t# ověřit predikci pro jiný batch size !!!!!!!!!!!!!!!!\n",
        "\t\tsuper(DeepLSTM_VAE, self).__init__()\n",
        "\n",
        "\t\tself.sequence_len = sequence_len\n",
        "\t\tself.n_features = n_features\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.hidden_size = hidden_size\n",
        "\t\tself.num_layers = num_layers\n",
        "\t\tself.use_cuda = use_cuda\n",
        "\n",
        "\t\tif self.use_cuda and torch.cuda.is_available():\n",
        "\t\t\tself.dtype = torch.cuda.FloatTensor\n",
        "\t\telse:\n",
        "\t\t\tself.dtype = torch.float32\n",
        "\n",
        "\t\tself.encoder_reshape = Reshape(out_shape=(self.sequence_len, self.n_features))\n",
        "\t\tself.encoder_lstm = nn.LSTM(\n",
        "\t\t\t\t\t\t\t\t\tinput_size=n_features,\n",
        "\t\t\t\t\t\t\t\t\thidden_size=hidden_size,\n",
        "\t\t\t\t\t\t\t\t\tnum_layers=num_layers,\n",
        "\t\t\t\t\t\t\t\t\tbatch_first=False,\n",
        "\t\t\t\t\t\t\t\t\tbidirectional=False\n",
        "\t\t\t\t\t\t\t\t\t) \n",
        "\t\tself.encoder_output = VariationalLayer(\n",
        "\t\t\t\t\t\t\t\t\tin_features=hidden_size, \n",
        "\t\t\t\t\t\t\t\t\tout_features=latent_dim, \n",
        "\t\t\t\t\t\t\t\t\treturn_KL=False\n",
        "\t\t\t\t\t\t\t\t\t)\n",
        "\n",
        "\t\tself.decoder_hidden = nn.Linear(\n",
        "\t\t\t\t\t\t\t\t\tin_features=latent_dim,\n",
        "\t\t\t\t\t\t\t\t\tout_features=hidden_size,\n",
        "\t\t\t\t\t\t\t\t\tbias=True\t\n",
        "\t\t\t\t\t\t\t\t\t)\n",
        "\t\tself.decoder_lstm = nn.LSTM(\n",
        "\t\t\t\t\t\t\t\t\tinput_size=1,\n",
        "\t\t\t\t\t\t\t\t\thidden_size=hidden_size,\n",
        "\t\t\t\t\t\t\t\t\tnum_layers=num_layers,\n",
        "\t\t\t\t\t\t\t\t\tbatch_first=False,\n",
        "\t\t\t\t\t\t\t\t\tbidirectional=False\n",
        "\t\t\t\t\t\t\t\t\t) \n",
        "\t\tself.decoder_output = RecurrentDecoderOutput(\n",
        "\t\t\t\t\t\t\t\t\tin_features=hidden_size,\n",
        "\t\t\t\t\t\t\t\t\tsequence_len=sequence_len,\n",
        "\t\t\t\t\t\t\t\t\tout_features=n_features,\n",
        "\t\t\t\t\t\t\t\t\tbias=True\n",
        "\t\t\t\t\t\t\t\t\t)\n",
        "\t\tself.decoder_input = torch.zeros(\n",
        "\t\t\t\t\t\t\t\t\tself.sequence_len, \n",
        "\t\t\t\t\t\t\t\t\tself.batch_size, \n",
        "\t\t\t\t\t\t\t\t\tself.n_features, \n",
        "\t\t\t\t\t\t\t\t\trequires_grad=True\n",
        "\t\t\t\t\t\t\t\t\t).type(self.dtype)\n",
        "\t\tself.decoder_c_0 = torch.zeros(\n",
        "\t\t\t\t\t\t\t\t\tself.num_layers,\n",
        "\t\t\t\t\t\t\t\t\tself.batch_size,\n",
        "\t\t\t\t\t\t\t\t\tself.hidden_size,\n",
        "\t\t\t\t\t\t\t\t\trequires_grad=True \n",
        "\t\t\t\t\t\t\t\t\t).type(self.dtype)\n",
        "\n",
        "\n",
        "\tdef encoder(self, x_in):\n",
        "\t\tx = self.encoder_reshape(x_in)\n",
        "\t\t#set_trace()\n",
        "\t\tx = x.permute(1, 0, 2)\n",
        "  \n",
        "\t\t_,(h_end, c_end) = self.encoder_lstm(x)\n",
        "\t\th_end = h_end[-1, :, :] # shape(batch_size, num_features)\n",
        "\t\treturn self.encoder_output(h_end)\n",
        "\n",
        "\tdef decoder(self, z_in):\n",
        "\t\th_state = self.decoder_hidden(z_in)\n",
        "\t\t#set_trace()\n",
        "\t\th_0 = torch.stack([h_state for _ in range(self.num_layers)])\n",
        "\t\tlstm_output, _ = self.decoder_lstm(self.decoder_input, (h_0, self.decoder_c_0))\n",
        "\t\tmu, sigma = self.decoder_output(lstm_output)\n",
        "\t\treturn mu, sigma\n",
        "\n",
        "\tdef forward(self, x_in):\n",
        "\t\tz, mu, sigma = self.encoder(x_in)\n",
        "\t\treturn self.decoder(z), mu, sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVm1UScE04ur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mod_l = DeepLSTM_VAE(\n",
        "    sequence_len=160, \n",
        "    n_features=1, \n",
        "    latent_dim=15, \n",
        "    hidden_size=128, \n",
        "    num_layers=1, \n",
        "    batch_size=300, \n",
        "    use_cuda=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxsH0oqA07-m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "fd95b138-b5ef-41a6-a8ef-d5d1b613232c"
      },
      "source": [
        "mod_l.cuda()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepLSTM_VAE(\n",
              "  (encoder_reshape): Reshape()\n",
              "  (encoder_lstm): LSTM(1, 128)\n",
              "  (encoder_output): VariationalLayer(\n",
              "    (mu): Linear(in_features=128, out_features=15, bias=True)\n",
              "    (rho): Linear(in_features=128, out_features=15, bias=True)\n",
              "    (softplus): Softplus(beta=1, threshold=20)\n",
              "  )\n",
              "  (decoder_hidden): Linear(in_features=15, out_features=128, bias=True)\n",
              "  (decoder_lstm): LSTM(1, 128)\n",
              "  (decoder_output): RecurrentDecoderOutput(\n",
              "    (mu): Linear(in_features=128, out_features=1, bias=True)\n",
              "    (rho): Linear(in_features=20480, out_features=1, bias=True)\n",
              "    (softplus): Softplus(beta=1, threshold=20)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qmOsInb1AaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8500e05a-a653-4f81-cad8-94a169179061"
      },
      "source": [
        "mod_l.load_state_dict(torch.load(\"models_and_losses/DeepLSTM_VAE_NLL_440ep_hidden-128_lr-{1e-3, 1e-4}_bs-300.pt\").state_dict())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-uKvKapsEVD3",
        "colab": {}
      },
      "source": [
        "DNN1 = nn.Sequential(\n",
        "            nn.Linear(in_features=15, out_features=128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(in_features=128, out_features=128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(in_features=128, out_features=4),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cks6n3k6C0fk",
        "colab": {}
      },
      "source": [
        "model = RNN_Encoder_Classifier(model=mod_l,clf= DNN1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O0LGYgIBC0h_",
        "outputId": "4a1d29cf-45a7-46ac-b7a3-9b418b7916ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.freeze_encoder()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder frozen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c01RM688EcPM"
      },
      "source": [
        "# training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JJTlqog5C0kT",
        "colab": {}
      },
      "source": [
        "optimizer= torch.optim.Adam(model.parameters(), lr=1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VIYUBwbJC0me",
        "outputId": "c94af3e6-35b5-414c-a8ec-5f03dcd52741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m1 = Trainer(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        loss_function=nn.CrossEntropyLoss(),\n",
        "        scheduler=torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20], gamma=0.1),\n",
        "        tensorboard=True,\n",
        "        model_name=\"DNN_on_LSTM-VAE_sampling_latent_space_UNFREEZE_lr-{1e-2,1e-3}_epochs-512\",\n",
        "        device=torch.device(\"cpu\"),\n",
        "        verbose=True\n",
        "        )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jt3Cy-HKC0op",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc3ff941-0b27-4815-ad58-91c10db4e40d"
      },
      "source": [
        "lh = m1(epochs=50, train_loader=train_loader, validation_loader=valid_loader)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py:1037: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Not within tolerance rtol=1e-05 atol=1e-05 at input[292, 1] (1.4314641952514648 vs. 1.5071825981140137) and 2046 other locations (99.95%)\n",
            "  check_tolerance, _force_outplace, True, _module_class)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py:1037: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Not within tolerance rtol=1e-05 atol=1e-05 at input[78, 1] (1.3177536725997925 vs. 1.4737449884414673) and 2045 other locations (99.90%)\n",
            "  check_tolerance, _force_outplace, True, _module_class)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py:1037: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Not within tolerance rtol=1e-05 atol=1e-05 at input[404, 1] (1.0771411657333374 vs. 1.4033302068710327) and 2046 other locations (99.95%)\n",
            "  check_tolerance, _force_outplace, True, _module_class)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py:1037: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Not within tolerance rtol=1e-05 atol=1e-05 at input[460, 2] (-2.1404683589935303 vs. -1.2786791324615479) and 2047 other locations (100.00%)\n",
            "  check_tolerance, _force_outplace, True, _module_class)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py:1037: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Not within tolerance rtol=1e-05 atol=1e-05 at input[394, 2] (-1.5562596321105957 vs. -2.5501046180725098) and 2046 other locations (99.95%)\n",
            "  check_tolerance, _force_outplace, True, _module_class)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py:1037: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Not within tolerance rtol=1e-05 atol=1e-05 at input[148, 2] (-1.4372135400772095 vs. -2.8011133670806885) and 2047 other locations (100.00%)\n",
            "  check_tolerance, _force_outplace, True, _module_class)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py:1037: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Not within tolerance rtol=1e-05 atol=1e-05 at input[273, 3] (-2.020813465118408 vs. -0.1588398665189743) and 2046 other locations (99.95%)\n",
            "  check_tolerance, _force_outplace, True, _module_class)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py:1037: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Not within tolerance rtol=1e-05 atol=1e-05 at input[345, 3] (-1.9080870151519775 vs. 0.05326216667890549) and 2046 other locations (99.95%)\n",
            "  check_tolerance, _force_outplace, True, _module_class)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py:1037: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Not within tolerance rtol=1e-05 atol=1e-05 at input[33, 3] (-0.7181336879730225 vs. -2.6352248191833496) and 2047 other locations (100.00%)\n",
            "  check_tolerance, _force_outplace, True, _module_class)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py:1037: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Not within tolerance rtol=1e-05 atol=1e-05 at input[270, 2] (-1.7192034721374512 vs. -3.4399478435516357) and 2046 other locations (99.95%)\n",
            "  check_tolerance, _force_outplace, True, _module_class)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/50], average_loss:0.8494, validation_loss:0.6870, val_accuracy:0.7020\n",
            "Epoch [2/50], average_loss:0.6575, validation_loss:0.5994, val_accuracy:0.7620\n",
            "Epoch [3/50], average_loss:0.6085, validation_loss:0.5660, val_accuracy:0.7663\n",
            "Epoch [4/50], average_loss:0.5818, validation_loss:0.5345, val_accuracy:0.7878\n",
            "Epoch [5/50], average_loss:0.5636, validation_loss:0.5203, val_accuracy:0.7921\n",
            "Epoch [6/50], average_loss:0.5498, validation_loss:0.5111, val_accuracy:0.7873\n",
            "Epoch [7/50], average_loss:0.5407, validation_loss:0.4985, val_accuracy:0.7927\n",
            "Epoch [8/50], average_loss:0.5335, validation_loss:0.4921, val_accuracy:0.8002\n",
            "Epoch [9/50], average_loss:0.5325, validation_loss:0.4859, val_accuracy:0.7953\n",
            "Epoch [10/50], average_loss:0.5301, validation_loss:0.4858, val_accuracy:0.7988\n",
            "Epoch [11/50], average_loss:0.5265, validation_loss:0.4789, val_accuracy:0.7979\n",
            "Epoch [12/50], average_loss:0.5191, validation_loss:0.4794, val_accuracy:0.8000\n",
            "Epoch [13/50], average_loss:0.5174, validation_loss:0.4779, val_accuracy:0.8011\n",
            "Epoch [14/50], average_loss:0.5145, validation_loss:0.4726, val_accuracy:0.8008\n",
            "Epoch [15/50], average_loss:0.5125, validation_loss:0.4722, val_accuracy:0.7995\n",
            "Epoch [16/50], average_loss:0.5134, validation_loss:0.4776, val_accuracy:0.7981\n",
            "Epoch [17/50], average_loss:0.5094, validation_loss:0.4690, val_accuracy:0.8011\n",
            "Epoch [18/50], average_loss:0.5062, validation_loss:0.4672, val_accuracy:0.8026\n",
            "Epoch [19/50], average_loss:0.5058, validation_loss:0.4699, val_accuracy:0.8005\n",
            "Epoch [20/50], average_loss:0.5050, validation_loss:0.4648, val_accuracy:0.8049\n",
            "Epoch [21/50], average_loss:0.4956, validation_loss:0.4640, val_accuracy:0.8022\n",
            "Epoch [22/50], average_loss:0.4952, validation_loss:0.4588, val_accuracy:0.8044\n",
            "Epoch [23/50], average_loss:0.4944, validation_loss:0.4593, val_accuracy:0.8029\n",
            "Epoch [24/50], average_loss:0.4927, validation_loss:0.4583, val_accuracy:0.8050\n",
            "Epoch [25/50], average_loss:0.4939, validation_loss:0.4571, val_accuracy:0.8042\n",
            "Epoch [26/50], average_loss:0.4912, validation_loss:0.4600, val_accuracy:0.8050\n",
            "Epoch [27/50], average_loss:0.4913, validation_loss:0.4573, val_accuracy:0.8048\n",
            "Epoch [28/50], average_loss:0.4920, validation_loss:0.4577, val_accuracy:0.8038\n",
            "Epoch [29/50], average_loss:0.4920, validation_loss:0.4577, val_accuracy:0.8051\n",
            "Epoch [30/50], average_loss:0.4903, validation_loss:0.4539, val_accuracy:0.8078\n",
            "Epoch [31/50], average_loss:0.4919, validation_loss:0.4611, val_accuracy:0.8048\n",
            "Epoch [32/50], average_loss:0.4901, validation_loss:0.4575, val_accuracy:0.8056\n",
            "Epoch [33/50], average_loss:0.4919, validation_loss:0.4550, val_accuracy:0.8077\n",
            "Epoch [34/50], average_loss:0.4904, validation_loss:0.4541, val_accuracy:0.8091\n",
            "Epoch [35/50], average_loss:0.4923, validation_loss:0.4559, val_accuracy:0.8099\n",
            "Epoch [36/50], average_loss:0.4900, validation_loss:0.4540, val_accuracy:0.8050\n",
            "Epoch [37/50], average_loss:0.4904, validation_loss:0.4545, val_accuracy:0.8071\n",
            "Epoch [38/50], average_loss:0.4899, validation_loss:0.4527, val_accuracy:0.8069\n",
            "Epoch [39/50], average_loss:0.4878, validation_loss:0.4585, val_accuracy:0.8058\n",
            "Epoch [40/50], average_loss:0.4877, validation_loss:0.4536, val_accuracy:0.8060\n",
            "Epoch [41/50], average_loss:0.4891, validation_loss:0.4547, val_accuracy:0.8064\n",
            "Epoch [42/50], average_loss:0.4907, validation_loss:0.4542, val_accuracy:0.8083\n",
            "Epoch [43/50], average_loss:0.4899, validation_loss:0.4570, val_accuracy:0.8065\n",
            "Epoch [44/50], average_loss:0.4888, validation_loss:0.4603, val_accuracy:0.8005\n",
            "Epoch [45/50], average_loss:0.4875, validation_loss:0.4493, val_accuracy:0.8092\n",
            "Epoch [46/50], average_loss:0.4882, validation_loss:0.4520, val_accuracy:0.8078\n",
            "Epoch [47/50], average_loss:0.4870, validation_loss:0.4524, val_accuracy:0.8068\n",
            "Epoch [48/50], average_loss:0.4842, validation_loss:0.4524, val_accuracy:0.8063\n",
            "Epoch [49/50], average_loss:0.4864, validation_loss:0.4574, val_accuracy:0.8066\n",
            "Epoch [50/50], average_loss:0.4858, validation_loss:0.4501, val_accuracy:0.8089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E_frZz0FC0rC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63ec223d-933d-41de-d7bc-b1c01bfc20fb"
      },
      "source": [
        "model.unfreeze_encoder()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder unfrozen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GES8qyTgC0vX",
        "colab": {}
      },
      "source": [
        "optimizer= torch.optim.Adam([{\"params\":model.model.parameters(), \"lr\":1e-5}, {\"params\":model.clf.parameters()}], lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q_AGp8vmC0x1",
        "colab": {}
      },
      "source": [
        "m1.optimizer = optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jHNxDsf6C00R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8a5c130-b302-4fd1-c2da-a16777b1470d"
      },
      "source": [
        "lh = m1(epochs=range(50,200), train_loader=train_loader, validation_loader=valid_loader)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [51/200], average_loss:0.4845, validation_loss:0.4440, val_accuracy:0.8109\n",
            "Epoch [52/200], average_loss:0.4822, validation_loss:0.4452, val_accuracy:0.8114\n",
            "Epoch [53/200], average_loss:0.4803, validation_loss:0.4441, val_accuracy:0.8089\n",
            "Epoch [54/200], average_loss:0.4761, validation_loss:0.4425, val_accuracy:0.8134\n",
            "Epoch [55/200], average_loss:0.4739, validation_loss:0.4406, val_accuracy:0.8127\n",
            "Epoch [56/200], average_loss:0.4736, validation_loss:0.4373, val_accuracy:0.8151\n",
            "Epoch [57/200], average_loss:0.4741, validation_loss:0.4375, val_accuracy:0.8138\n",
            "Epoch [58/200], average_loss:0.4701, validation_loss:0.4392, val_accuracy:0.8118\n",
            "Epoch [59/200], average_loss:0.4688, validation_loss:0.4340, val_accuracy:0.8163\n",
            "Epoch [60/200], average_loss:0.4697, validation_loss:0.4357, val_accuracy:0.8150\n",
            "Epoch [61/200], average_loss:0.4671, validation_loss:0.4370, val_accuracy:0.8163\n",
            "Epoch [62/200], average_loss:0.4687, validation_loss:0.4368, val_accuracy:0.8127\n",
            "Epoch [63/200], average_loss:0.4667, validation_loss:0.4332, val_accuracy:0.8172\n",
            "Epoch [64/200], average_loss:0.4647, validation_loss:0.4323, val_accuracy:0.8179\n",
            "Epoch [65/200], average_loss:0.4633, validation_loss:0.4315, val_accuracy:0.8159\n",
            "Epoch [66/200], average_loss:0.4631, validation_loss:0.4330, val_accuracy:0.8161\n",
            "Epoch [67/200], average_loss:0.4610, validation_loss:0.4304, val_accuracy:0.8162\n",
            "Epoch [68/200], average_loss:0.4615, validation_loss:0.4304, val_accuracy:0.8195\n",
            "Epoch [69/200], average_loss:0.4592, validation_loss:0.4334, val_accuracy:0.8142\n",
            "Epoch [70/200], average_loss:0.4626, validation_loss:0.4271, val_accuracy:0.8176\n",
            "Epoch [71/200], average_loss:0.4622, validation_loss:0.4308, val_accuracy:0.8173\n",
            "Epoch [72/200], average_loss:0.4601, validation_loss:0.4319, val_accuracy:0.8150\n",
            "Epoch [73/200], average_loss:0.4604, validation_loss:0.4307, val_accuracy:0.8182\n",
            "Epoch [74/200], average_loss:0.4584, validation_loss:0.4295, val_accuracy:0.8166\n",
            "Epoch [75/200], average_loss:0.4588, validation_loss:0.4297, val_accuracy:0.8174\n",
            "Epoch [76/200], average_loss:0.4574, validation_loss:0.4212, val_accuracy:0.8215\n",
            "Epoch [77/200], average_loss:0.4560, validation_loss:0.4263, val_accuracy:0.8192\n",
            "Epoch [78/200], average_loss:0.4555, validation_loss:0.4213, val_accuracy:0.8217\n",
            "Epoch [79/200], average_loss:0.4568, validation_loss:0.4250, val_accuracy:0.8179\n",
            "Epoch [80/200], average_loss:0.4552, validation_loss:0.4262, val_accuracy:0.8207\n",
            "Epoch [81/200], average_loss:0.4527, validation_loss:0.4276, val_accuracy:0.8160\n",
            "Epoch [82/200], average_loss:0.4537, validation_loss:0.4234, val_accuracy:0.8162\n",
            "Epoch [83/200], average_loss:0.4537, validation_loss:0.4201, val_accuracy:0.8211\n",
            "Epoch [84/200], average_loss:0.4545, validation_loss:0.4220, val_accuracy:0.8189\n",
            "Epoch [85/200], average_loss:0.4529, validation_loss:0.4218, val_accuracy:0.8200\n",
            "Epoch [86/200], average_loss:0.4534, validation_loss:0.4213, val_accuracy:0.8208\n",
            "Epoch [87/200], average_loss:0.4508, validation_loss:0.4203, val_accuracy:0.8201\n",
            "Epoch [88/200], average_loss:0.4510, validation_loss:0.4226, val_accuracy:0.8184\n",
            "Epoch [89/200], average_loss:0.4523, validation_loss:0.4232, val_accuracy:0.8188\n",
            "Epoch [90/200], average_loss:0.4499, validation_loss:0.4252, val_accuracy:0.8154\n",
            "Epoch [91/200], average_loss:0.4508, validation_loss:0.4203, val_accuracy:0.8199\n",
            "Epoch [92/200], average_loss:0.4493, validation_loss:0.4250, val_accuracy:0.8189\n",
            "Epoch [93/200], average_loss:0.4507, validation_loss:0.4239, val_accuracy:0.8185\n",
            "Epoch [94/200], average_loss:0.4487, validation_loss:0.4191, val_accuracy:0.8224\n",
            "Epoch [95/200], average_loss:0.4492, validation_loss:0.4239, val_accuracy:0.8173\n",
            "Epoch [96/200], average_loss:0.4473, validation_loss:0.4200, val_accuracy:0.8190\n",
            "Epoch [97/200], average_loss:0.4473, validation_loss:0.4240, val_accuracy:0.8192\n",
            "Epoch [98/200], average_loss:0.4478, validation_loss:0.4202, val_accuracy:0.8203\n",
            "Epoch [99/200], average_loss:0.4468, validation_loss:0.4180, val_accuracy:0.8211\n",
            "Epoch [100/200], average_loss:0.4475, validation_loss:0.4168, val_accuracy:0.8209\n",
            "Epoch [101/200], average_loss:0.4479, validation_loss:0.4151, val_accuracy:0.8222\n",
            "Epoch [102/200], average_loss:0.4455, validation_loss:0.4191, val_accuracy:0.8202\n",
            "Epoch [103/200], average_loss:0.4456, validation_loss:0.4193, val_accuracy:0.8198\n",
            "Epoch [104/200], average_loss:0.4431, validation_loss:0.4194, val_accuracy:0.8203\n",
            "Epoch [105/200], average_loss:0.4442, validation_loss:0.4177, val_accuracy:0.8183\n",
            "Epoch [106/200], average_loss:0.4453, validation_loss:0.4192, val_accuracy:0.8194\n",
            "Epoch [107/200], average_loss:0.4460, validation_loss:0.4188, val_accuracy:0.8187\n",
            "Epoch [108/200], average_loss:0.4444, validation_loss:0.4164, val_accuracy:0.8237\n",
            "Epoch [109/200], average_loss:0.4449, validation_loss:0.4136, val_accuracy:0.8245\n",
            "Epoch [110/200], average_loss:0.4446, validation_loss:0.4149, val_accuracy:0.8229\n",
            "Epoch [111/200], average_loss:0.4449, validation_loss:0.4168, val_accuracy:0.8228\n",
            "Epoch [112/200], average_loss:0.4436, validation_loss:0.4169, val_accuracy:0.8218\n",
            "Epoch [113/200], average_loss:0.4425, validation_loss:0.4159, val_accuracy:0.8215\n",
            "Epoch [114/200], average_loss:0.4412, validation_loss:0.4136, val_accuracy:0.8215\n",
            "Epoch [115/200], average_loss:0.4427, validation_loss:0.4147, val_accuracy:0.8228\n",
            "Epoch [116/200], average_loss:0.4437, validation_loss:0.4149, val_accuracy:0.8229\n",
            "Epoch [117/200], average_loss:0.4408, validation_loss:0.4132, val_accuracy:0.8223\n",
            "Epoch [118/200], average_loss:0.4396, validation_loss:0.4155, val_accuracy:0.8206\n",
            "Epoch [119/200], average_loss:0.4420, validation_loss:0.4179, val_accuracy:0.8164\n",
            "Epoch [120/200], average_loss:0.4405, validation_loss:0.4102, val_accuracy:0.8243\n",
            "Epoch [121/200], average_loss:0.4391, validation_loss:0.4164, val_accuracy:0.8218\n",
            "Epoch [122/200], average_loss:0.4409, validation_loss:0.4135, val_accuracy:0.8206\n",
            "Epoch [123/200], average_loss:0.4420, validation_loss:0.4146, val_accuracy:0.8229\n",
            "Epoch [124/200], average_loss:0.4402, validation_loss:0.4161, val_accuracy:0.8216\n",
            "Epoch [125/200], average_loss:0.4397, validation_loss:0.4170, val_accuracy:0.8192\n",
            "Epoch [126/200], average_loss:0.4395, validation_loss:0.4141, val_accuracy:0.8234\n",
            "Epoch [127/200], average_loss:0.4389, validation_loss:0.4186, val_accuracy:0.8197\n",
            "Epoch [128/200], average_loss:0.4374, validation_loss:0.4123, val_accuracy:0.8219\n",
            "Epoch [129/200], average_loss:0.4374, validation_loss:0.4184, val_accuracy:0.8183\n",
            "Epoch [130/200], average_loss:0.4348, validation_loss:0.4115, val_accuracy:0.8228\n",
            "Epoch [131/200], average_loss:0.4376, validation_loss:0.4120, val_accuracy:0.8245\n",
            "Epoch [132/200], average_loss:0.4378, validation_loss:0.4091, val_accuracy:0.8232\n",
            "Epoch [133/200], average_loss:0.4360, validation_loss:0.4144, val_accuracy:0.8198\n",
            "Epoch [134/200], average_loss:0.4377, validation_loss:0.4155, val_accuracy:0.8201\n",
            "Epoch [135/200], average_loss:0.4360, validation_loss:0.4104, val_accuracy:0.8232\n",
            "Epoch [136/200], average_loss:0.4358, validation_loss:0.4103, val_accuracy:0.8235\n",
            "Epoch [137/200], average_loss:0.4371, validation_loss:0.4094, val_accuracy:0.8251\n",
            "Epoch [138/200], average_loss:0.4355, validation_loss:0.4146, val_accuracy:0.8207\n",
            "Epoch [139/200], average_loss:0.4341, validation_loss:0.4130, val_accuracy:0.8202\n",
            "Epoch [140/200], average_loss:0.4346, validation_loss:0.4102, val_accuracy:0.8246\n",
            "Epoch [141/200], average_loss:0.4341, validation_loss:0.4140, val_accuracy:0.8216\n",
            "Epoch [142/200], average_loss:0.4339, validation_loss:0.4127, val_accuracy:0.8214\n",
            "Epoch [143/200], average_loss:0.4345, validation_loss:0.4081, val_accuracy:0.8243\n",
            "Epoch [144/200], average_loss:0.4344, validation_loss:0.4099, val_accuracy:0.8247\n",
            "Epoch [145/200], average_loss:0.4342, validation_loss:0.4078, val_accuracy:0.8235\n",
            "Epoch [146/200], average_loss:0.4349, validation_loss:0.4106, val_accuracy:0.8224\n",
            "Epoch [147/200], average_loss:0.4335, validation_loss:0.4096, val_accuracy:0.8223\n",
            "Epoch [148/200], average_loss:0.4351, validation_loss:0.4099, val_accuracy:0.8231\n",
            "Epoch [149/200], average_loss:0.4326, validation_loss:0.4109, val_accuracy:0.8205\n",
            "Epoch [150/200], average_loss:0.4335, validation_loss:0.4064, val_accuracy:0.8258\n",
            "Epoch [151/200], average_loss:0.4315, validation_loss:0.4127, val_accuracy:0.8212\n",
            "Epoch [152/200], average_loss:0.4328, validation_loss:0.4109, val_accuracy:0.8241\n",
            "Epoch [153/200], average_loss:0.4314, validation_loss:0.4074, val_accuracy:0.8249\n",
            "Epoch [154/200], average_loss:0.4322, validation_loss:0.4070, val_accuracy:0.8231\n",
            "Epoch [155/200], average_loss:0.4318, validation_loss:0.4069, val_accuracy:0.8247\n",
            "Epoch [156/200], average_loss:0.4322, validation_loss:0.4069, val_accuracy:0.8218\n",
            "Epoch [157/200], average_loss:0.4322, validation_loss:0.4105, val_accuracy:0.8233\n",
            "Epoch [158/200], average_loss:0.4317, validation_loss:0.4117, val_accuracy:0.8225\n",
            "Epoch [159/200], average_loss:0.4325, validation_loss:0.4068, val_accuracy:0.8260\n",
            "Epoch [160/200], average_loss:0.4324, validation_loss:0.4075, val_accuracy:0.8261\n",
            "Epoch [161/200], average_loss:0.4306, validation_loss:0.4042, val_accuracy:0.8270\n",
            "Epoch [162/200], average_loss:0.4301, validation_loss:0.4075, val_accuracy:0.8226\n",
            "Epoch [163/200], average_loss:0.4297, validation_loss:0.4067, val_accuracy:0.8245\n",
            "Epoch [164/200], average_loss:0.4292, validation_loss:0.4104, val_accuracy:0.8231\n",
            "Epoch [165/200], average_loss:0.4286, validation_loss:0.4035, val_accuracy:0.8253\n",
            "Epoch [166/200], average_loss:0.4314, validation_loss:0.4079, val_accuracy:0.8251\n",
            "Epoch [167/200], average_loss:0.4301, validation_loss:0.4059, val_accuracy:0.8240\n",
            "Epoch [168/200], average_loss:0.4298, validation_loss:0.4089, val_accuracy:0.8204\n",
            "Epoch [169/200], average_loss:0.4311, validation_loss:0.4058, val_accuracy:0.8251\n",
            "Epoch [170/200], average_loss:0.4304, validation_loss:0.4088, val_accuracy:0.8247\n",
            "Epoch [171/200], average_loss:0.4285, validation_loss:0.4105, val_accuracy:0.8231\n",
            "Epoch [172/200], average_loss:0.4288, validation_loss:0.4111, val_accuracy:0.8227\n",
            "Epoch [173/200], average_loss:0.4295, validation_loss:0.4036, val_accuracy:0.8270\n",
            "Epoch [174/200], average_loss:0.4283, validation_loss:0.4066, val_accuracy:0.8239\n",
            "Epoch [175/200], average_loss:0.4278, validation_loss:0.4032, val_accuracy:0.8262\n",
            "Epoch [176/200], average_loss:0.4277, validation_loss:0.4054, val_accuracy:0.8248\n",
            "Epoch [177/200], average_loss:0.4265, validation_loss:0.4050, val_accuracy:0.8257\n",
            "Epoch [178/200], average_loss:0.4268, validation_loss:0.4031, val_accuracy:0.8258\n",
            "Epoch [179/200], average_loss:0.4273, validation_loss:0.4099, val_accuracy:0.8232\n",
            "Epoch [180/200], average_loss:0.4266, validation_loss:0.4026, val_accuracy:0.8248\n",
            "Epoch [181/200], average_loss:0.4279, validation_loss:0.4028, val_accuracy:0.8239\n",
            "Epoch [182/200], average_loss:0.4273, validation_loss:0.4084, val_accuracy:0.8226\n",
            "Epoch [183/200], average_loss:0.4284, validation_loss:0.4061, val_accuracy:0.8251\n",
            "Epoch [184/200], average_loss:0.4270, validation_loss:0.4052, val_accuracy:0.8239\n",
            "Epoch [185/200], average_loss:0.4270, validation_loss:0.4024, val_accuracy:0.8271\n",
            "Epoch [186/200], average_loss:0.4250, validation_loss:0.4000, val_accuracy:0.8273\n",
            "Epoch [187/200], average_loss:0.4274, validation_loss:0.4040, val_accuracy:0.8252\n",
            "Epoch [188/200], average_loss:0.4268, validation_loss:0.4030, val_accuracy:0.8268\n",
            "Epoch [189/200], average_loss:0.4260, validation_loss:0.4054, val_accuracy:0.8249\n",
            "Epoch [190/200], average_loss:0.4263, validation_loss:0.4032, val_accuracy:0.8251\n",
            "Epoch [191/200], average_loss:0.4263, validation_loss:0.4057, val_accuracy:0.8246\n",
            "Epoch [192/200], average_loss:0.4249, validation_loss:0.4017, val_accuracy:0.8239\n",
            "Epoch [193/200], average_loss:0.4264, validation_loss:0.4063, val_accuracy:0.8236\n",
            "Epoch [194/200], average_loss:0.4238, validation_loss:0.4022, val_accuracy:0.8251\n",
            "Epoch [195/200], average_loss:0.4250, validation_loss:0.4052, val_accuracy:0.8263\n",
            "Epoch [196/200], average_loss:0.4260, validation_loss:0.4062, val_accuracy:0.8244\n",
            "Epoch [197/200], average_loss:0.4266, validation_loss:0.4048, val_accuracy:0.8271\n",
            "Epoch [198/200], average_loss:0.4262, validation_loss:0.4010, val_accuracy:0.8245\n",
            "Epoch [199/200], average_loss:0.4264, validation_loss:0.4047, val_accuracy:0.8251\n",
            "Epoch [200/200], average_loss:0.4238, validation_loss:0.4034, val_accuracy:0.8257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TgBdiEGtC021",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    x_pred = np.argmax(m1.model(torch.tensor(X_test).float().to(m1.device)).cpu().detach(), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mWG_zKzuC0tn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c10a4d85-cc3c-484a-a008-251ef65ff8bb"
      },
      "source": [
        "f1_score(y_true=y_test, y_pred=x_pred, average=\"macro\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7946867981823128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGtPrLsE2vTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0c54816-0d94-452c-d23c-3bb3926ee071"
      },
      "source": [
        "accuracy_score(y_true=y_test, y_pred=x_pred)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8314412045889101"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO6U1FJ_2vWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7b2b6d86-d5ea-4601-bca0-474a1e467341"
      },
      "source": [
        "confusion_matrix(y_true=y_test, y_pred=x_pred)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2358, 1729,   32,  116],\n",
              "       [ 354, 9949,   36,  106],\n",
              "       [  20,   47,  397,   15],\n",
              "       [ 187,  164,   15, 1211]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g2Iorkb2vZi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "830ecf0c-8ff6-4e08-a4a3-3849c2182d73"
      },
      "source": [
        "torch.save(m1.model, \"DNN_on_RVAE_sampling_latent_space_UNFREEZE_m.IV_lr-{1e-2,1e-3}_epochs-512.pt\")\n",
        "torch.save(m1.model.state_dict(), \"DNN_on_RVAE_sampling_latent_space_UNFREEZE_m.IV_lr-{1e-2,1e-3}_epochs-512_state_dict.pt\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type RNN_Encoder_Classifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type DeepLSTM_VAE. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdUTvE1g2vcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lae_a49t2vgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM8YojUF2vfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}