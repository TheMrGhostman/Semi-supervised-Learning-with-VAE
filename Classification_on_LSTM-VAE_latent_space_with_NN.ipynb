{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCOGgPDrM9zN"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import time\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from utils.inference import Trainer, plot_loss\n",
    "from utils.models import DNN\n",
    "import utils.datasets as d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2VWYVWNR0_K"
   },
   "source": [
    "# With sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lthUbpn6R5mm"
   },
   "outputs": [],
   "source": [
    "X = np.vstack((np.load(\"data/sequenced_data_for_VAE_length-160_stride-10_pt1.npy\"),\n",
    "               np.load(\"data/sequenced_data_for_VAE_length-160_stride-10_pt2.npy\")))\n",
    "y = np.load(\"data/sequenced_data_for_VAE_length-160_stride-10_targets.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSbBqmZrSFuu"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uP7mTPvqSF5x"
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1o58gaXd8Jlf"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYKHTsaRSF3_"
   },
   "outputs": [],
   "source": [
    "train = d.H_alphaSequences(X_train, y_train)\n",
    "valid = d.H_alphaSequences(X_valid, y_valid)\n",
    "test = d.H_alphaSequences(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jGGuGd3SF2K"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train, batch_size=512, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset = valid, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hddr9EK9RNkH"
   },
   "source": [
    "## Loading Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKomVcQoPRFq"
   },
   "outputs": [],
   "source": [
    "VAE = torch.load(\"models_and_losses/DeepLSTM_VAE_NLL_440ep_hidden-128_lr-{1e-3, 1e-4}_bs-300.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepLSTM_VAE(\n",
       "  (encoder_reshape): Reshape()\n",
       "  (encoder_lstm): LSTM(1, 128)\n",
       "  (encoder_output): VariationalLayer(\n",
       "    (mu): Linear(in_features=128, out_features=15, bias=True)\n",
       "    (rho): Linear(in_features=128, out_features=15, bias=True)\n",
       "    (softplus): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (decoder_hidden): Linear(in_features=15, out_features=128, bias=True)\n",
       "  (decoder_lstm): LSTM(1, 128)\n",
       "  (decoder_output): RecurrentDecoderOutput(\n",
       "    (mu): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (rho): Linear(in_features=20480, out_features=1, bias=True)\n",
       "    (softplus): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQrz4pcRRvZC"
   },
   "source": [
    "## Freezing Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FepPrHmi5kKh"
   },
   "outputs": [],
   "source": [
    "class Encoder_Classifier(nn.Module):\n",
    "    def __init__(self, encoder, clf):\n",
    "        super(Encoder_Classifier, self).__init__()\n",
    "        self.encoder=encoder\n",
    "        self.clf = clf\n",
    "        self.frozen_encoder = False\n",
    "\n",
    "    def freeze_encoder(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.frozen_encoder = True\n",
    "        print(\"Encoder frozen.\")\n",
    "\n",
    "    def unfreeze_encoder(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.frozen_encoder = False\n",
    "        print(\"Encoder unfrozen.\")\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Z, mu, sigma = self.encoder(X)\n",
    "        return self.clf(Z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Encoder_Classifier(nn.Module):\n",
    "    def __init__(self, model, clf):\n",
    "        super(RNN_Encoder_Classifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.clf = clf\n",
    "        self.frozen_encoder = False\n",
    "\n",
    "    def freeze_encoder(self):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.frozen_encoder = True\n",
    "        print(\"Encoder frozen.\")\n",
    "\n",
    "    def unfreeze_encoder(self):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.frozen_encoder = False\n",
    "        print(\"Encoder unfrozen.\")\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Z, mu, sigma = self.model.encoder(X)\n",
    "        return self.clf(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f0r4jLHe5tPy"
   },
   "outputs": [],
   "source": [
    "DNN1 = nn.Sequential(\n",
    "            nn.Linear(in_features=15, out_features=64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=64, out_features=128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=128, out_features=4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-sou9uan7bFD",
    "outputId": "473dc211-21a7-4a1c-f9b7-1a9418fcc45e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder frozen.\n"
     ]
    }
   ],
   "source": [
    "model = RNN_Encoder_Classifier(model=VAE, clf = DNN1)\n",
    "model.freeze_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xw7AbVFD7TKP"
   },
   "outputs": [],
   "source": [
    "optimizer= torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "hfD_WT5J7Yb-",
    "outputId": "0803e7a8-0aab-455e-9878-315ed7f840ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "m1 = Trainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_function=nn.CrossEntropyLoss(),\n",
    "        scheduler=torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30], gamma=0.1),\n",
    "        tensorboard=True,\n",
    "        model_name=\"DNN_on_DeepLSTM_VAE_NLL_440ep_hidden-128_lr-{1e-3, 1e-4}_bs-300\",\n",
    "        verbose=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mNFqptqd7Y_2",
    "outputId": "98abb786-b97f-40f7-81b2-40ce2d0e9a86",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
      "\t%eps : Float(512, 15) = aten::randn_like(%sigma, %138, %139, %140, %141), scope: RNN_Encoder_Classifier/VariationalLayer # Z:\\Semi-supervised-Learning-with-VAE\\layers.py:35:0\n",
      "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[482, 1] (1.4707341194152832 vs. 1.3906586170196533) and 2045 other locations (99.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[393, 1] (1.2430009841918945 vs. 1.1320732831954956) and 2045 other locations (99.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[400, 1] (1.222729206085205 vs. 1.452066421508789) and 2047 other locations (100.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[459, 2] (-1.9321264028549194 vs. -2.3474013805389404) and 2046 other locations (99.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[38, 2] (-1.5012937784194946 vs. -2.3472354412078857) and 2046 other locations (99.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[78, 3] (-0.29780063033103943 vs. -1.7716994285583496) and 2046 other locations (99.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[321, 3] (-0.1500224620103836 vs. -1.8040331602096558) and 2046 other locations (99.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[425, 3] (-2.605839252471924 vs. -0.6284067630767822) and 2046 other locations (99.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[77, 3] (0.04765582084655762 vs. -1.697166919708252) and 2047 other locations (100.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[304, 2] (-0.5527427196502686 vs. -2.7266955375671387) and 2047 other locations (100.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], average_loss:0.8453, validation_loss:0.6827, val_accuracy:0.7662\n",
      "Epoch [2/100], average_loss:0.6273, validation_loss:0.6152, val_accuracy:0.7403\n",
      "Epoch [3/100], average_loss:0.5886, validation_loss:0.5968, val_accuracy:0.7662\n",
      "Epoch [4/100], average_loss:0.5701, validation_loss:0.5654, val_accuracy:0.8052\n",
      "Epoch [5/100], average_loss:0.5540, validation_loss:0.5463, val_accuracy:0.7922\n",
      "Epoch [6/100], average_loss:0.5275, validation_loss:0.5148, val_accuracy:0.7013\n",
      "Epoch [7/100], average_loss:0.4897, validation_loss:0.4750, val_accuracy:0.8182\n",
      "Epoch [8/100], average_loss:0.4798, validation_loss:0.4794, val_accuracy:0.7662\n",
      "Epoch [9/100], average_loss:0.4702, validation_loss:0.4651, val_accuracy:0.7792\n",
      "Epoch [10/100], average_loss:0.4612, validation_loss:0.4579, val_accuracy:0.9091\n",
      "Epoch [11/100], average_loss:0.4597, validation_loss:0.4626, val_accuracy:0.7403\n",
      "Epoch [12/100], average_loss:0.4561, validation_loss:0.4527, val_accuracy:0.8571\n",
      "Epoch [13/100], average_loss:0.4538, validation_loss:0.4493, val_accuracy:0.8052\n",
      "Epoch [14/100], average_loss:0.4539, validation_loss:0.4474, val_accuracy:0.8052\n",
      "Epoch [15/100], average_loss:0.4516, validation_loss:0.4384, val_accuracy:0.9091\n",
      "Epoch [16/100], average_loss:0.4503, validation_loss:0.4535, val_accuracy:0.7662\n",
      "Epoch [17/100], average_loss:0.4481, validation_loss:0.4568, val_accuracy:0.7143\n",
      "Epoch [18/100], average_loss:0.4470, validation_loss:0.4440, val_accuracy:0.7922\n",
      "Epoch [19/100], average_loss:0.4446, validation_loss:0.4382, val_accuracy:0.8831\n",
      "Epoch [20/100], average_loss:0.4451, validation_loss:0.4565, val_accuracy:0.7143\n",
      "Epoch [21/100], average_loss:0.4434, validation_loss:0.4462, val_accuracy:0.7662\n",
      "Epoch [22/100], average_loss:0.4428, validation_loss:0.4441, val_accuracy:0.8182\n",
      "Epoch [23/100], average_loss:0.4413, validation_loss:0.4409, val_accuracy:0.7403\n",
      "Epoch [24/100], average_loss:0.4430, validation_loss:0.4460, val_accuracy:0.7922\n",
      "Epoch [25/100], average_loss:0.4418, validation_loss:0.4427, val_accuracy:0.8182\n",
      "Epoch [26/100], average_loss:0.4405, validation_loss:0.4398, val_accuracy:0.8182\n",
      "Epoch [27/100], average_loss:0.4387, validation_loss:0.4466, val_accuracy:0.8312\n",
      "Epoch [28/100], average_loss:0.4387, validation_loss:0.4477, val_accuracy:0.7662\n",
      "Epoch [29/100], average_loss:0.4388, validation_loss:0.4435, val_accuracy:0.8052\n",
      "Epoch [30/100], average_loss:0.4396, validation_loss:0.4319, val_accuracy:0.7532\n",
      "Epoch [31/100], average_loss:0.4297, validation_loss:0.4264, val_accuracy:0.7532\n",
      "Epoch [32/100], average_loss:0.4280, validation_loss:0.4310, val_accuracy:0.8182\n",
      "Epoch [33/100], average_loss:0.4284, validation_loss:0.4277, val_accuracy:0.8831\n",
      "Epoch [34/100], average_loss:0.4275, validation_loss:0.4329, val_accuracy:0.7532\n",
      "Epoch [35/100], average_loss:0.4270, validation_loss:0.4293, val_accuracy:0.8442\n",
      "Epoch [36/100], average_loss:0.4264, validation_loss:0.4296, val_accuracy:0.8312\n",
      "Epoch [37/100], average_loss:0.4284, validation_loss:0.4307, val_accuracy:0.8701\n",
      "Epoch [38/100], average_loss:0.4283, validation_loss:0.4323, val_accuracy:0.7792\n",
      "Epoch [39/100], average_loss:0.4271, validation_loss:0.4316, val_accuracy:0.7532\n",
      "Epoch [40/100], average_loss:0.4274, validation_loss:0.4300, val_accuracy:0.7792\n",
      "Epoch [41/100], average_loss:0.4272, validation_loss:0.4272, val_accuracy:0.8312\n",
      "Epoch [42/100], average_loss:0.4268, validation_loss:0.4300, val_accuracy:0.8182\n",
      "Epoch [43/100], average_loss:0.4268, validation_loss:0.4351, val_accuracy:0.7662\n",
      "Epoch [44/100], average_loss:0.4272, validation_loss:0.4291, val_accuracy:0.8442\n",
      "Epoch [45/100], average_loss:0.4261, validation_loss:0.4289, val_accuracy:0.8442\n",
      "Epoch [46/100], average_loss:0.4264, validation_loss:0.4270, val_accuracy:0.8442\n",
      "Epoch [47/100], average_loss:0.4263, validation_loss:0.4271, val_accuracy:0.8442\n",
      "Epoch [48/100], average_loss:0.4266, validation_loss:0.4325, val_accuracy:0.7273\n",
      "Epoch [49/100], average_loss:0.4261, validation_loss:0.4324, val_accuracy:0.8052\n",
      "Epoch [50/100], average_loss:0.4255, validation_loss:0.4288, val_accuracy:0.8442\n",
      "Epoch [51/100], average_loss:0.4264, validation_loss:0.4286, val_accuracy:0.8052\n",
      "Epoch [52/100], average_loss:0.4263, validation_loss:0.4281, val_accuracy:0.7792\n",
      "Epoch [53/100], average_loss:0.4265, validation_loss:0.4293, val_accuracy:0.8182\n",
      "Epoch [54/100], average_loss:0.4265, validation_loss:0.4249, val_accuracy:0.8571\n",
      "Epoch [55/100], average_loss:0.4257, validation_loss:0.4299, val_accuracy:0.8182\n",
      "Epoch [56/100], average_loss:0.4255, validation_loss:0.4245, val_accuracy:0.8701\n",
      "Epoch [57/100], average_loss:0.4250, validation_loss:0.4262, val_accuracy:0.8442\n",
      "Epoch [58/100], average_loss:0.4253, validation_loss:0.4313, val_accuracy:0.7922\n",
      "Epoch [59/100], average_loss:0.4246, validation_loss:0.4341, val_accuracy:0.7532\n",
      "Epoch [60/100], average_loss:0.4251, validation_loss:0.4287, val_accuracy:0.7792\n",
      "Epoch [61/100], average_loss:0.4262, validation_loss:0.4311, val_accuracy:0.7922\n",
      "Epoch [62/100], average_loss:0.4267, validation_loss:0.4277, val_accuracy:0.8052\n",
      "Epoch [63/100], average_loss:0.4244, validation_loss:0.4295, val_accuracy:0.8442\n",
      "Epoch [64/100], average_loss:0.4261, validation_loss:0.4279, val_accuracy:0.8442\n",
      "Epoch [65/100], average_loss:0.4244, validation_loss:0.4267, val_accuracy:0.8442\n",
      "Epoch [66/100], average_loss:0.4247, validation_loss:0.4294, val_accuracy:0.8312\n",
      "Epoch [67/100], average_loss:0.4242, validation_loss:0.4262, val_accuracy:0.8831\n",
      "Epoch [68/100], average_loss:0.4239, validation_loss:0.4292, val_accuracy:0.8442\n",
      "Epoch [69/100], average_loss:0.4257, validation_loss:0.4282, val_accuracy:0.8052\n",
      "Epoch [70/100], average_loss:0.4242, validation_loss:0.4287, val_accuracy:0.8442\n",
      "Epoch [71/100], average_loss:0.4235, validation_loss:0.4298, val_accuracy:0.7662\n",
      "Epoch [72/100], average_loss:0.4249, validation_loss:0.4288, val_accuracy:0.7792\n",
      "Epoch [73/100], average_loss:0.4246, validation_loss:0.4300, val_accuracy:0.7532\n",
      "Epoch [74/100], average_loss:0.4244, validation_loss:0.4315, val_accuracy:0.8052\n",
      "Epoch [75/100], average_loss:0.4239, validation_loss:0.4249, val_accuracy:0.8442\n",
      "Epoch [76/100], average_loss:0.4239, validation_loss:0.4312, val_accuracy:0.7922\n",
      "Epoch [77/100], average_loss:0.4245, validation_loss:0.4296, val_accuracy:0.8182\n",
      "Epoch [78/100], average_loss:0.4237, validation_loss:0.4280, val_accuracy:0.7922\n",
      "Epoch [79/100], average_loss:0.4243, validation_loss:0.4270, val_accuracy:0.7922\n",
      "Epoch [80/100], average_loss:0.4235, validation_loss:0.4280, val_accuracy:0.8182\n",
      "Epoch [81/100], average_loss:0.4262, validation_loss:0.4222, val_accuracy:0.8182\n",
      "Epoch [82/100], average_loss:0.4251, validation_loss:0.4291, val_accuracy:0.7273\n",
      "Epoch [83/100], average_loss:0.4241, validation_loss:0.4239, val_accuracy:0.8442\n",
      "Epoch [84/100], average_loss:0.4231, validation_loss:0.4284, val_accuracy:0.8831\n",
      "Epoch [85/100], average_loss:0.4234, validation_loss:0.4247, val_accuracy:0.8571\n",
      "Epoch [86/100], average_loss:0.4229, validation_loss:0.4275, val_accuracy:0.7662\n",
      "Epoch [87/100], average_loss:0.4224, validation_loss:0.4308, val_accuracy:0.7662\n",
      "Epoch [88/100], average_loss:0.4236, validation_loss:0.4243, val_accuracy:0.8312\n",
      "Epoch [89/100], average_loss:0.4229, validation_loss:0.4302, val_accuracy:0.7662\n",
      "Epoch [90/100], average_loss:0.4240, validation_loss:0.4266, val_accuracy:0.8701\n",
      "Epoch [91/100], average_loss:0.4231, validation_loss:0.4266, val_accuracy:0.8442\n",
      "Epoch [92/100], average_loss:0.4227, validation_loss:0.4211, val_accuracy:0.8961\n",
      "Epoch [93/100], average_loss:0.4242, validation_loss:0.4254, val_accuracy:0.8831\n",
      "Epoch [94/100], average_loss:0.4227, validation_loss:0.4246, val_accuracy:0.8571\n",
      "Epoch [95/100], average_loss:0.4232, validation_loss:0.4270, val_accuracy:0.8182\n",
      "Epoch [96/100], average_loss:0.4226, validation_loss:0.4316, val_accuracy:0.8182\n",
      "Epoch [97/100], average_loss:0.4245, validation_loss:0.4248, val_accuracy:0.8831\n",
      "Epoch [98/100], average_loss:0.4222, validation_loss:0.4318, val_accuracy:0.8052\n",
      "Epoch [99/100], average_loss:0.4230, validation_loss:0.4267, val_accuracy:0.8052\n",
      "Epoch [100/100], average_loss:0.4228, validation_loss:0.4229, val_accuracy:0.8831\n"
     ]
    }
   ],
   "source": [
    "lh = m1(epochs=100, train_loader=train_loader, validation_loader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_qgCvyEN8N-"
   },
   "outputs": [],
   "source": [
    "X_test = np.load(\"data/mu_lstm_test.npy\")\n",
    "y_test = np.load(\"data/labels_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dl-v7vuW7ZGJ"
   },
   "outputs": [],
   "source": [
    "#m1.tb.close()\n",
    "\n",
    "m1.model.eval()\n",
    "with torch.no_grad():\n",
    "    x_pred = np.argmax(m1.model.clf(torch.tensor(X_test).float().to(m1.device)).cpu().detach(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nVJcVBba7ZQj",
    "outputId": "ad9c9adf-e291-4a61-a997-f61280318e43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6910981336881359"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true=y_test, y_pred=x_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UpfUu-pxOFiW",
    "outputId": "93e7f8c2-3088-4f86-fd14-ba7e644eb74d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7047681644359465"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "TBNwia05OFl4",
    "outputId": "bcfd8546-69ad-44f6-8f01-f3451a830d2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2343, 1453,   90,  349],\n",
       "       [2161, 7669,  118,  497],\n",
       "       [  19,    7,  417,   36],\n",
       "       [ 158,   46,   10, 1363]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true=y_test, y_pred=x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjnpeT8y7ZEE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sigmoid. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(m1.model.clf, \"models_and_losses/DeepLSTM_VAE_NLL_440ep_hidden-128_lr-{1e-3, 1e-4}_bs-300+DNN_on_VAE_sampling_latent_space_m.IV_lr-{1e-2,1e-3}_bs-512_epoch-100.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/200], average_loss:0.4226, validation_loss:0.4284, val_accuracy:0.7532\n",
      "Epoch [102/200], average_loss:0.4217, validation_loss:0.4254, val_accuracy:0.8442\n",
      "Epoch [103/200], average_loss:0.4236, validation_loss:0.4313, val_accuracy:0.7532\n",
      "Epoch [104/200], average_loss:0.4221, validation_loss:0.4260, val_accuracy:0.7922\n",
      "Epoch [105/200], average_loss:0.4213, validation_loss:0.4270, val_accuracy:0.8182\n",
      "Epoch [106/200], average_loss:0.4221, validation_loss:0.4259, val_accuracy:0.8571\n",
      "Epoch [107/200], average_loss:0.4221, validation_loss:0.4269, val_accuracy:0.7792\n",
      "Epoch [108/200], average_loss:0.4225, validation_loss:0.4274, val_accuracy:0.7922\n",
      "Epoch [109/200], average_loss:0.4219, validation_loss:0.4271, val_accuracy:0.7662\n",
      "Epoch [110/200], average_loss:0.4223, validation_loss:0.4281, val_accuracy:0.7532\n",
      "Epoch [111/200], average_loss:0.4220, validation_loss:0.4231, val_accuracy:0.8052\n",
      "Epoch [112/200], average_loss:0.4206, validation_loss:0.4342, val_accuracy:0.7532\n",
      "Epoch [113/200], average_loss:0.4219, validation_loss:0.4276, val_accuracy:0.7922\n",
      "Epoch [114/200], average_loss:0.4214, validation_loss:0.4268, val_accuracy:0.8182\n",
      "Epoch [115/200], average_loss:0.4211, validation_loss:0.4301, val_accuracy:0.8312\n",
      "Epoch [116/200], average_loss:0.4215, validation_loss:0.4298, val_accuracy:0.7143\n",
      "Epoch [117/200], average_loss:0.4212, validation_loss:0.4281, val_accuracy:0.7273\n",
      "Epoch [118/200], average_loss:0.4208, validation_loss:0.4279, val_accuracy:0.7662\n",
      "Epoch [119/200], average_loss:0.4223, validation_loss:0.4228, val_accuracy:0.8182\n",
      "Epoch [120/200], average_loss:0.4214, validation_loss:0.4255, val_accuracy:0.8442\n",
      "Epoch [121/200], average_loss:0.4219, validation_loss:0.4245, val_accuracy:0.8052\n",
      "Epoch [122/200], average_loss:0.4223, validation_loss:0.4266, val_accuracy:0.8182\n",
      "Epoch [123/200], average_loss:0.4204, validation_loss:0.4285, val_accuracy:0.6883\n",
      "Epoch [124/200], average_loss:0.4209, validation_loss:0.4281, val_accuracy:0.7662\n",
      "Epoch [125/200], average_loss:0.4205, validation_loss:0.4253, val_accuracy:0.8571\n",
      "Epoch [126/200], average_loss:0.4220, validation_loss:0.4261, val_accuracy:0.8052\n",
      "Epoch [127/200], average_loss:0.4202, validation_loss:0.4278, val_accuracy:0.8182\n",
      "Epoch [128/200], average_loss:0.4202, validation_loss:0.4327, val_accuracy:0.8052\n",
      "Epoch [129/200], average_loss:0.4212, validation_loss:0.4234, val_accuracy:0.8182\n",
      "Epoch [130/200], average_loss:0.4210, validation_loss:0.4282, val_accuracy:0.7792\n",
      "Epoch [131/200], average_loss:0.4211, validation_loss:0.4264, val_accuracy:0.8312\n",
      "Epoch [132/200], average_loss:0.4213, validation_loss:0.4272, val_accuracy:0.8182\n",
      "Epoch [133/200], average_loss:0.4199, validation_loss:0.4249, val_accuracy:0.8701\n",
      "Epoch [134/200], average_loss:0.4208, validation_loss:0.4236, val_accuracy:0.8312\n",
      "Epoch [135/200], average_loss:0.4215, validation_loss:0.4273, val_accuracy:0.8442\n",
      "Epoch [136/200], average_loss:0.4221, validation_loss:0.4237, val_accuracy:0.8571\n",
      "Epoch [137/200], average_loss:0.4203, validation_loss:0.4278, val_accuracy:0.7792\n",
      "Epoch [138/200], average_loss:0.4205, validation_loss:0.4255, val_accuracy:0.7922\n",
      "Epoch [139/200], average_loss:0.4190, validation_loss:0.4228, val_accuracy:0.8182\n",
      "Epoch [140/200], average_loss:0.4198, validation_loss:0.4254, val_accuracy:0.8442\n",
      "Epoch [141/200], average_loss:0.4214, validation_loss:0.4265, val_accuracy:0.7792\n",
      "Epoch [142/200], average_loss:0.4200, validation_loss:0.4239, val_accuracy:0.8312\n",
      "Epoch [143/200], average_loss:0.4199, validation_loss:0.4272, val_accuracy:0.8312\n",
      "Epoch [144/200], average_loss:0.4202, validation_loss:0.4251, val_accuracy:0.8442\n",
      "Epoch [145/200], average_loss:0.4194, validation_loss:0.4272, val_accuracy:0.8312\n",
      "Epoch [146/200], average_loss:0.4195, validation_loss:0.4270, val_accuracy:0.8442\n",
      "Epoch [147/200], average_loss:0.4209, validation_loss:0.4254, val_accuracy:0.8052\n",
      "Epoch [148/200], average_loss:0.4196, validation_loss:0.4240, val_accuracy:0.8442\n",
      "Epoch [149/200], average_loss:0.4194, validation_loss:0.4290, val_accuracy:0.7403\n",
      "Epoch [150/200], average_loss:0.4200, validation_loss:0.4208, val_accuracy:0.8442\n",
      "Epoch [151/200], average_loss:0.4193, validation_loss:0.4263, val_accuracy:0.8442\n",
      "Epoch [152/200], average_loss:0.4199, validation_loss:0.4211, val_accuracy:0.8182\n",
      "Epoch [153/200], average_loss:0.4204, validation_loss:0.4249, val_accuracy:0.8571\n",
      "Epoch [154/200], average_loss:0.4193, validation_loss:0.4227, val_accuracy:0.8442\n",
      "Epoch [155/200], average_loss:0.4197, validation_loss:0.4263, val_accuracy:0.8182\n",
      "Epoch [156/200], average_loss:0.4202, validation_loss:0.4284, val_accuracy:0.7792\n",
      "Epoch [157/200], average_loss:0.4183, validation_loss:0.4259, val_accuracy:0.7792\n",
      "Epoch [158/200], average_loss:0.4192, validation_loss:0.4233, val_accuracy:0.8831\n",
      "Epoch [159/200], average_loss:0.4186, validation_loss:0.4252, val_accuracy:0.8312\n",
      "Epoch [160/200], average_loss:0.4199, validation_loss:0.4221, val_accuracy:0.8442\n",
      "Epoch [161/200], average_loss:0.4191, validation_loss:0.4325, val_accuracy:0.7532\n",
      "Epoch [162/200], average_loss:0.4191, validation_loss:0.4246, val_accuracy:0.7662\n",
      "Epoch [163/200], average_loss:0.4191, validation_loss:0.4278, val_accuracy:0.7792\n",
      "Epoch [164/200], average_loss:0.4193, validation_loss:0.4245, val_accuracy:0.8701\n",
      "Epoch [165/200], average_loss:0.4197, validation_loss:0.4259, val_accuracy:0.7922\n",
      "Epoch [166/200], average_loss:0.4194, validation_loss:0.4218, val_accuracy:0.8312\n",
      "Epoch [167/200], average_loss:0.4181, validation_loss:0.4190, val_accuracy:0.8831\n",
      "Epoch [168/200], average_loss:0.4187, validation_loss:0.4280, val_accuracy:0.7792\n",
      "Epoch [169/200], average_loss:0.4182, validation_loss:0.4208, val_accuracy:0.8442\n",
      "Epoch [170/200], average_loss:0.4189, validation_loss:0.4231, val_accuracy:0.8701\n",
      "Epoch [171/200], average_loss:0.4185, validation_loss:0.4228, val_accuracy:0.8312\n",
      "Epoch [172/200], average_loss:0.4193, validation_loss:0.4280, val_accuracy:0.7792\n",
      "Epoch [173/200], average_loss:0.4184, validation_loss:0.4230, val_accuracy:0.8571\n",
      "Epoch [174/200], average_loss:0.4200, validation_loss:0.4237, val_accuracy:0.8442\n",
      "Epoch [175/200], average_loss:0.4190, validation_loss:0.4254, val_accuracy:0.8442\n",
      "Epoch [176/200], average_loss:0.4184, validation_loss:0.4277, val_accuracy:0.7273\n",
      "Epoch [177/200], average_loss:0.4179, validation_loss:0.4267, val_accuracy:0.7922\n",
      "Epoch [178/200], average_loss:0.4177, validation_loss:0.4244, val_accuracy:0.8701\n",
      "Epoch [179/200], average_loss:0.4182, validation_loss:0.4241, val_accuracy:0.7922\n",
      "Epoch [180/200], average_loss:0.4182, validation_loss:0.4242, val_accuracy:0.8442\n",
      "Epoch [181/200], average_loss:0.4190, validation_loss:0.4251, val_accuracy:0.8182\n",
      "Epoch [182/200], average_loss:0.4177, validation_loss:0.4259, val_accuracy:0.7792\n",
      "Epoch [183/200], average_loss:0.4173, validation_loss:0.4251, val_accuracy:0.8312\n",
      "Epoch [184/200], average_loss:0.4192, validation_loss:0.4218, val_accuracy:0.8571\n",
      "Epoch [185/200], average_loss:0.4179, validation_loss:0.4238, val_accuracy:0.8312\n",
      "Epoch [186/200], average_loss:0.4183, validation_loss:0.4211, val_accuracy:0.8701\n",
      "Epoch [187/200], average_loss:0.4186, validation_loss:0.4239, val_accuracy:0.7922\n",
      "Epoch [188/200], average_loss:0.4189, validation_loss:0.4191, val_accuracy:0.9351\n",
      "Epoch [189/200], average_loss:0.4182, validation_loss:0.4246, val_accuracy:0.7792\n",
      "Epoch [190/200], average_loss:0.4189, validation_loss:0.4304, val_accuracy:0.7013\n",
      "Epoch [191/200], average_loss:0.4180, validation_loss:0.4293, val_accuracy:0.8052\n",
      "Epoch [192/200], average_loss:0.4181, validation_loss:0.4295, val_accuracy:0.7792\n",
      "Epoch [193/200], average_loss:0.4182, validation_loss:0.4242, val_accuracy:0.8442\n",
      "Epoch [194/200], average_loss:0.4180, validation_loss:0.4222, val_accuracy:0.8831\n",
      "Epoch [195/200], average_loss:0.4166, validation_loss:0.4267, val_accuracy:0.8182\n",
      "Epoch [196/200], average_loss:0.4185, validation_loss:0.4254, val_accuracy:0.8312\n",
      "Epoch [197/200], average_loss:0.4182, validation_loss:0.4239, val_accuracy:0.7532\n",
      "Epoch [198/200], average_loss:0.4166, validation_loss:0.4201, val_accuracy:0.8182\n",
      "Epoch [199/200], average_loss:0.4184, validation_loss:0.4233, val_accuracy:0.7792\n",
      "Epoch [200/200], average_loss:0.4184, validation_loss:0.4209, val_accuracy:0.8312\n"
     ]
    }
   ],
   "source": [
    "lh = m1(epochs=range(100,200), train_loader=train_loader, validation_loader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dl-v7vuW7ZGJ"
   },
   "outputs": [],
   "source": [
    "m1.tb.close()\n",
    "\n",
    "m1.model.eval()\n",
    "with torch.no_grad():\n",
    "    x_pred = np.argmax(m1.model.clf(torch.tensor(X_test).float().to(m1.device)).cpu().detach(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nVJcVBba7ZQj",
    "outputId": "ad9c9adf-e291-4a61-a997-f61280318e43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6910981336881359"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true=y_test, y_pred=x_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UpfUu-pxOFiW",
    "outputId": "93e7f8c2-3088-4f86-fd14-ba7e644eb74d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7047681644359465"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "TBNwia05OFl4",
    "outputId": "bcfd8546-69ad-44f6-8f01-f3451a830d2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2386, 1450,   89,  310],\n",
       "       [2177, 7651,  127,  490],\n",
       "       [  28,    5,  413,   33],\n",
       "       [ 170,   49,   13, 1345]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true=y_test, y_pred=x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(m1.model.clf, \"models_and_losses/DeepLSTM_VAE_NLL_440ep_hidden-128_lr-{1e-3, 1e-4}_bs-300+DNN_on_VAE_sampling_latent_space_m.IV_lr-{1e-2,1e-3}_bs-512_epoch-200.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bs 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train, batch_size=512, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset = valid, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f0r4jLHe5tPy"
   },
   "outputs": [],
   "source": [
    "DNN2 = nn.Sequential(\n",
    "            nn.Linear(in_features=15, out_features=128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=128, out_features=4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-sou9uan7bFD",
    "outputId": "473dc211-21a7-4a1c-f9b7-1a9418fcc45e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder frozen.\n"
     ]
    }
   ],
   "source": [
    "model2 = RNN_Encoder_Classifier(VAE, clf = DNN2)\n",
    "model2.freeze_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xw7AbVFD7TKP"
   },
   "outputs": [],
   "source": [
    "optimizer= torch.optim.Adam(model2.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "hfD_WT5J7Yb-",
    "outputId": "0803e7a8-0aab-455e-9878-315ed7f840ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "m2 = Trainer(\n",
    "        model=model2,\n",
    "        optimizer=optimizer,\n",
    "        loss_function=nn.CrossEntropyLoss(),\n",
    "        scheduler=torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,60], gamma=0.1),\n",
    "        tensorboard=True,\n",
    "        model_name=\"DNN_on_DeepLSTM_VAE_NLL_440ep_hidden-128_lr-{1e-3, 1e-4}_bs-300\",\n",
    "        verbose=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
      "\t%eps : Float(512, 15) = aten::randn_like(%sigma, %134, %135, %136, %137), scope: RNN_Encoder_Classifier/VariationalLayer # Z:\\Semi-supervised-Learning-with-VAE\\layers.py:35:0\n",
      "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[230, 1] (1.4038562774658203 vs. 2.1659274101257324) and 2047 other locations (100.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[47, 2] (-3.022970199584961 vs. -2.1053969860076904) and 2047 other locations (100.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[98, 2] (-1.991999864578247 vs. -0.5851178765296936) and 2047 other locations (100.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[188, 3] (-0.030672769993543625 vs. -1.3933759927749634) and 2046 other locations (99.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[477, 3] (-0.05741731822490692 vs. -2.1460468769073486) and 2047 other locations (100.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[263, 3] (0.26686906814575195 vs. -1.6341761350631714) and 2047 other locations (100.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[387, 3] (-1.5428951978683472 vs. -3.815608501434326) and 2046 other locations (99.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[412, 3] (-1.2010873556137085 vs. -3.3314106464385986) and 2047 other locations (100.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[325, 2] (-0.5502916574478149 vs. -3.5112648010253906) and 2047 other locations (100.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "C:\\Users\\ghost_000\\Miniconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\jit\\__init__.py:1007: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[339, 3] (-0.12782162427902222 vs. -2.383141040802002) and 2047 other locations (100.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], average_loss:0.7723, validation_loss:0.6685, val_accuracy:0.7792\n",
      "Epoch [2/100], average_loss:0.6666, validation_loss:0.6489, val_accuracy:0.8052\n",
      "Epoch [3/100], average_loss:0.6330, validation_loss:0.6122, val_accuracy:0.8052\n",
      "Epoch [4/100], average_loss:0.6035, validation_loss:0.5894, val_accuracy:0.8442\n",
      "Epoch [5/100], average_loss:0.5833, validation_loss:0.5804, val_accuracy:0.8312\n",
      "Epoch [6/100], average_loss:0.5685, validation_loss:0.5652, val_accuracy:0.7662\n",
      "Epoch [7/100], average_loss:0.5586, validation_loss:0.5519, val_accuracy:0.7662\n",
      "Epoch [8/100], average_loss:0.5470, validation_loss:0.5461, val_accuracy:0.8312\n",
      "Epoch [9/100], average_loss:0.5424, validation_loss:0.5443, val_accuracy:0.7662\n",
      "Epoch [10/100], average_loss:0.5371, validation_loss:0.5352, val_accuracy:0.8571\n",
      "Epoch [11/100], average_loss:0.5299, validation_loss:0.5247, val_accuracy:0.7792\n",
      "Epoch [12/100], average_loss:0.5223, validation_loss:0.5171, val_accuracy:0.7792\n",
      "Epoch [13/100], average_loss:0.5122, validation_loss:0.5072, val_accuracy:0.8312\n",
      "Epoch [14/100], average_loss:0.5001, validation_loss:0.4964, val_accuracy:0.7273\n",
      "Epoch [15/100], average_loss:0.4890, validation_loss:0.4875, val_accuracy:0.7403\n",
      "Epoch [16/100], average_loss:0.4832, validation_loss:0.4810, val_accuracy:0.7792\n",
      "Epoch [17/100], average_loss:0.4821, validation_loss:0.4799, val_accuracy:0.7143\n",
      "Epoch [18/100], average_loss:0.4767, validation_loss:0.4760, val_accuracy:0.8182\n",
      "Epoch [19/100], average_loss:0.4758, validation_loss:0.4739, val_accuracy:0.7273\n",
      "Epoch [20/100], average_loss:0.4726, validation_loss:0.4712, val_accuracy:0.8052\n",
      "Epoch [21/100], average_loss:0.4719, validation_loss:0.4691, val_accuracy:0.7662\n",
      "Epoch [22/100], average_loss:0.4701, validation_loss:0.4712, val_accuracy:0.7792\n",
      "Epoch [23/100], average_loss:0.4692, validation_loss:0.4665, val_accuracy:0.8182\n",
      "Epoch [24/100], average_loss:0.4695, validation_loss:0.4795, val_accuracy:0.7403\n",
      "Epoch [25/100], average_loss:0.4694, validation_loss:0.4617, val_accuracy:0.7792\n",
      "Epoch [26/100], average_loss:0.4670, validation_loss:0.4671, val_accuracy:0.7922\n",
      "Epoch [27/100], average_loss:0.4665, validation_loss:0.4699, val_accuracy:0.8312\n",
      "Epoch [28/100], average_loss:0.4670, validation_loss:0.4668, val_accuracy:0.8182\n",
      "Epoch [29/100], average_loss:0.4672, validation_loss:0.4655, val_accuracy:0.8182\n",
      "Epoch [30/100], average_loss:0.4662, validation_loss:0.4655, val_accuracy:0.7532\n",
      "Epoch [31/100], average_loss:0.4610, validation_loss:0.4589, val_accuracy:0.8442\n",
      "Epoch [32/100], average_loss:0.4589, validation_loss:0.4596, val_accuracy:0.8571\n",
      "Epoch [33/100], average_loss:0.4593, validation_loss:0.4657, val_accuracy:0.6883\n",
      "Epoch [34/100], average_loss:0.4592, validation_loss:0.4625, val_accuracy:0.7532\n",
      "Epoch [35/100], average_loss:0.4582, validation_loss:0.4601, val_accuracy:0.8312\n",
      "Epoch [36/100], average_loss:0.4577, validation_loss:0.4563, val_accuracy:0.8442\n",
      "Epoch [37/100], average_loss:0.4586, validation_loss:0.4637, val_accuracy:0.7792\n",
      "Epoch [38/100], average_loss:0.4585, validation_loss:0.4636, val_accuracy:0.7532\n",
      "Epoch [39/100], average_loss:0.4582, validation_loss:0.4599, val_accuracy:0.7532\n",
      "Epoch [40/100], average_loss:0.4588, validation_loss:0.4588, val_accuracy:0.8052\n",
      "Epoch [41/100], average_loss:0.4577, validation_loss:0.4591, val_accuracy:0.8312\n",
      "Epoch [42/100], average_loss:0.4572, validation_loss:0.4614, val_accuracy:0.7922\n",
      "Epoch [43/100], average_loss:0.4590, validation_loss:0.4629, val_accuracy:0.7143\n",
      "Epoch [44/100], average_loss:0.4585, validation_loss:0.4599, val_accuracy:0.7922\n",
      "Epoch [45/100], average_loss:0.4580, validation_loss:0.4602, val_accuracy:0.7403\n",
      "Epoch [46/100], average_loss:0.4577, validation_loss:0.4556, val_accuracy:0.8831\n",
      "Epoch [47/100], average_loss:0.4573, validation_loss:0.4590, val_accuracy:0.7662\n",
      "Epoch [48/100], average_loss:0.4572, validation_loss:0.4564, val_accuracy:0.7922\n",
      "Epoch [49/100], average_loss:0.4575, validation_loss:0.4610, val_accuracy:0.7922\n",
      "Epoch [50/100], average_loss:0.4576, validation_loss:0.4603, val_accuracy:0.7922\n",
      "Epoch [51/100], average_loss:0.4567, validation_loss:0.4604, val_accuracy:0.7662\n",
      "Epoch [52/100], average_loss:0.4570, validation_loss:0.4526, val_accuracy:0.8701\n",
      "Epoch [53/100], average_loss:0.4575, validation_loss:0.4590, val_accuracy:0.7403\n",
      "Epoch [54/100], average_loss:0.4573, validation_loss:0.4591, val_accuracy:0.8182\n",
      "Epoch [55/100], average_loss:0.4563, validation_loss:0.4571, val_accuracy:0.8052\n",
      "Epoch [56/100], average_loss:0.4569, validation_loss:0.4595, val_accuracy:0.7662\n",
      "Epoch [57/100], average_loss:0.4573, validation_loss:0.4600, val_accuracy:0.8182\n",
      "Epoch [58/100], average_loss:0.4570, validation_loss:0.4555, val_accuracy:0.8052\n",
      "Epoch [59/100], average_loss:0.4565, validation_loss:0.4549, val_accuracy:0.8961\n",
      "Epoch [60/100], average_loss:0.4564, validation_loss:0.4598, val_accuracy:0.8442\n",
      "Epoch [61/100], average_loss:0.4551, validation_loss:0.4581, val_accuracy:0.7532\n",
      "Epoch [62/100], average_loss:0.4555, validation_loss:0.4573, val_accuracy:0.8052\n",
      "Epoch [63/100], average_loss:0.4553, validation_loss:0.4552, val_accuracy:0.8571\n",
      "Epoch [64/100], average_loss:0.4549, validation_loss:0.4597, val_accuracy:0.7792\n",
      "Epoch [65/100], average_loss:0.4560, validation_loss:0.4593, val_accuracy:0.8571\n",
      "Epoch [66/100], average_loss:0.4569, validation_loss:0.4566, val_accuracy:0.8182\n",
      "Epoch [67/100], average_loss:0.4554, validation_loss:0.4595, val_accuracy:0.7792\n",
      "Epoch [68/100], average_loss:0.4555, validation_loss:0.4544, val_accuracy:0.8312\n",
      "Epoch [69/100], average_loss:0.4564, validation_loss:0.4560, val_accuracy:0.7662\n",
      "Epoch [70/100], average_loss:0.4550, validation_loss:0.4622, val_accuracy:0.6883\n",
      "Epoch [71/100], average_loss:0.4553, validation_loss:0.4588, val_accuracy:0.8182\n",
      "Epoch [72/100], average_loss:0.4560, validation_loss:0.4518, val_accuracy:0.8831\n",
      "Epoch [73/100], average_loss:0.4562, validation_loss:0.4529, val_accuracy:0.8442\n",
      "Epoch [74/100], average_loss:0.4548, validation_loss:0.4541, val_accuracy:0.8571\n",
      "Epoch [75/100], average_loss:0.4556, validation_loss:0.4583, val_accuracy:0.7532\n",
      "Epoch [76/100], average_loss:0.4556, validation_loss:0.4555, val_accuracy:0.8571\n",
      "Epoch [77/100], average_loss:0.4546, validation_loss:0.4513, val_accuracy:0.8701\n",
      "Epoch [78/100], average_loss:0.4561, validation_loss:0.4597, val_accuracy:0.8052\n",
      "Epoch [79/100], average_loss:0.4563, validation_loss:0.4552, val_accuracy:0.8182\n",
      "Epoch [80/100], average_loss:0.4554, validation_loss:0.4563, val_accuracy:0.8442\n",
      "Epoch [81/100], average_loss:0.4547, validation_loss:0.4562, val_accuracy:0.8442\n",
      "Epoch [82/100], average_loss:0.4559, validation_loss:0.4554, val_accuracy:0.8312\n",
      "Epoch [83/100], average_loss:0.4555, validation_loss:0.4561, val_accuracy:0.8182\n",
      "Epoch [84/100], average_loss:0.4553, validation_loss:0.4603, val_accuracy:0.7792\n",
      "Epoch [85/100], average_loss:0.4560, validation_loss:0.4634, val_accuracy:0.7403\n",
      "Epoch [86/100], average_loss:0.4550, validation_loss:0.4549, val_accuracy:0.8312\n",
      "Epoch [87/100], average_loss:0.4547, validation_loss:0.4569, val_accuracy:0.7532\n",
      "Epoch [88/100], average_loss:0.4556, validation_loss:0.4579, val_accuracy:0.8312\n",
      "Epoch [89/100], average_loss:0.4561, validation_loss:0.4572, val_accuracy:0.7013\n",
      "Epoch [90/100], average_loss:0.4551, validation_loss:0.4529, val_accuracy:0.9091\n",
      "Epoch [91/100], average_loss:0.4554, validation_loss:0.4555, val_accuracy:0.7792\n",
      "Epoch [92/100], average_loss:0.4547, validation_loss:0.4580, val_accuracy:0.7922\n",
      "Epoch [93/100], average_loss:0.4545, validation_loss:0.4532, val_accuracy:0.8701\n",
      "Epoch [94/100], average_loss:0.4561, validation_loss:0.4564, val_accuracy:0.8312\n",
      "Epoch [95/100], average_loss:0.4554, validation_loss:0.4544, val_accuracy:0.8182\n",
      "Epoch [96/100], average_loss:0.4553, validation_loss:0.4563, val_accuracy:0.7792\n",
      "Epoch [97/100], average_loss:0.4553, validation_loss:0.4540, val_accuracy:0.8571\n",
      "Epoch [98/100], average_loss:0.4561, validation_loss:0.4533, val_accuracy:0.8442\n",
      "Epoch [99/100], average_loss:0.4549, validation_loss:0.4593, val_accuracy:0.7792\n",
      "Epoch [100/100], average_loss:0.4550, validation_loss:0.4570, val_accuracy:0.7792\n"
     ]
    }
   ],
   "source": [
    "lh = m2(epochs=100, train_loader=train_loader, validation_loader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/200], average_loss:0.4233, validation_loss:0.4299, val_accuracy:0.8052\n",
      "Epoch [102/200], average_loss:0.4242, validation_loss:0.4277, val_accuracy:0.8442\n",
      "Epoch [103/200], average_loss:0.4237, validation_loss:0.4278, val_accuracy:0.9091\n",
      "Epoch [104/200], average_loss:0.4230, validation_loss:0.4331, val_accuracy:0.7792\n",
      "Epoch [105/200], average_loss:0.4247, validation_loss:0.4316, val_accuracy:0.7403\n",
      "Epoch [106/200], average_loss:0.4239, validation_loss:0.4306, val_accuracy:0.8052\n",
      "Epoch [107/200], average_loss:0.4232, validation_loss:0.4306, val_accuracy:0.8571\n",
      "Epoch [108/200], average_loss:0.4236, validation_loss:0.4272, val_accuracy:0.8312\n",
      "Epoch [109/200], average_loss:0.4234, validation_loss:0.4258, val_accuracy:0.8571\n",
      "Epoch [110/200], average_loss:0.4245, validation_loss:0.4274, val_accuracy:0.8831\n",
      "Epoch [111/200], average_loss:0.4236, validation_loss:0.4302, val_accuracy:0.8182\n",
      "Epoch [112/200], average_loss:0.4240, validation_loss:0.4328, val_accuracy:0.7662\n",
      "Epoch [113/200], average_loss:0.4239, validation_loss:0.4285, val_accuracy:0.8571\n",
      "Epoch [114/200], average_loss:0.4244, validation_loss:0.4345, val_accuracy:0.7532\n",
      "Epoch [115/200], average_loss:0.4244, validation_loss:0.4328, val_accuracy:0.7532\n",
      "Epoch [116/200], average_loss:0.4237, validation_loss:0.4283, val_accuracy:0.8312\n",
      "Epoch [117/200], average_loss:0.4232, validation_loss:0.4275, val_accuracy:0.8312\n",
      "Epoch [118/200], average_loss:0.4242, validation_loss:0.4323, val_accuracy:0.7403\n",
      "Epoch [119/200], average_loss:0.4219, validation_loss:0.4284, val_accuracy:0.7532\n",
      "Epoch [120/200], average_loss:0.4244, validation_loss:0.4285, val_accuracy:0.8442\n",
      "Epoch [121/200], average_loss:0.4233, validation_loss:0.4291, val_accuracy:0.8182\n",
      "Epoch [122/200], average_loss:0.4236, validation_loss:0.4281, val_accuracy:0.7662\n",
      "Epoch [123/200], average_loss:0.4238, validation_loss:0.4264, val_accuracy:0.8312\n",
      "Epoch [124/200], average_loss:0.4239, validation_loss:0.4329, val_accuracy:0.7922\n",
      "Epoch [125/200], average_loss:0.4237, validation_loss:0.4292, val_accuracy:0.8571\n",
      "Epoch [126/200], average_loss:0.4250, validation_loss:0.4304, val_accuracy:0.8312\n",
      "Epoch [127/200], average_loss:0.4234, validation_loss:0.4265, val_accuracy:0.8312\n",
      "Epoch [128/200], average_loss:0.4238, validation_loss:0.4276, val_accuracy:0.8571\n",
      "Epoch [129/200], average_loss:0.4235, validation_loss:0.4312, val_accuracy:0.7532\n",
      "Epoch [130/200], average_loss:0.4245, validation_loss:0.4282, val_accuracy:0.8312\n",
      "Epoch [131/200], average_loss:0.4243, validation_loss:0.4311, val_accuracy:0.8701\n",
      "Epoch [132/200], average_loss:0.4231, validation_loss:0.4296, val_accuracy:0.8442\n",
      "Epoch [133/200], average_loss:0.4229, validation_loss:0.4329, val_accuracy:0.7532\n",
      "Epoch [134/200], average_loss:0.4232, validation_loss:0.4292, val_accuracy:0.7403\n",
      "Epoch [135/200], average_loss:0.4233, validation_loss:0.4315, val_accuracy:0.7532\n",
      "Epoch [136/200], average_loss:0.4229, validation_loss:0.4330, val_accuracy:0.7662\n",
      "Epoch [137/200], average_loss:0.4232, validation_loss:0.4262, val_accuracy:0.8701\n",
      "Epoch [138/200], average_loss:0.4238, validation_loss:0.4296, val_accuracy:0.7922\n",
      "Epoch [139/200], average_loss:0.4220, validation_loss:0.4274, val_accuracy:0.8442\n",
      "Epoch [140/200], average_loss:0.4246, validation_loss:0.4285, val_accuracy:0.8312\n",
      "Epoch [141/200], average_loss:0.4242, validation_loss:0.4264, val_accuracy:0.8312\n",
      "Epoch [142/200], average_loss:0.4233, validation_loss:0.4334, val_accuracy:0.6883\n",
      "Epoch [143/200], average_loss:0.4224, validation_loss:0.4294, val_accuracy:0.7922\n",
      "Epoch [144/200], average_loss:0.4236, validation_loss:0.4272, val_accuracy:0.7922\n",
      "Epoch [145/200], average_loss:0.4233, validation_loss:0.4265, val_accuracy:0.8571\n",
      "Epoch [146/200], average_loss:0.4244, validation_loss:0.4303, val_accuracy:0.7662\n",
      "Epoch [147/200], average_loss:0.4237, validation_loss:0.4286, val_accuracy:0.7662\n",
      "Epoch [148/200], average_loss:0.4238, validation_loss:0.4279, val_accuracy:0.8052\n",
      "Epoch [149/200], average_loss:0.4229, validation_loss:0.4253, val_accuracy:0.8571\n",
      "Epoch [150/200], average_loss:0.4242, validation_loss:0.4304, val_accuracy:0.8442\n",
      "Epoch [151/200], average_loss:0.4232, validation_loss:0.4304, val_accuracy:0.8831\n",
      "Epoch [152/200], average_loss:0.4215, validation_loss:0.4293, val_accuracy:0.7922\n",
      "Epoch [153/200], average_loss:0.4233, validation_loss:0.4247, val_accuracy:0.8831\n",
      "Epoch [154/200], average_loss:0.4224, validation_loss:0.4310, val_accuracy:0.7792\n",
      "Epoch [155/200], average_loss:0.4245, validation_loss:0.4325, val_accuracy:0.7922\n",
      "Epoch [156/200], average_loss:0.4239, validation_loss:0.4306, val_accuracy:0.7922\n",
      "Epoch [157/200], average_loss:0.4240, validation_loss:0.4302, val_accuracy:0.7662\n",
      "Epoch [158/200], average_loss:0.4229, validation_loss:0.4325, val_accuracy:0.7792\n",
      "Epoch [159/200], average_loss:0.4241, validation_loss:0.4291, val_accuracy:0.7792\n",
      "Epoch [160/200], average_loss:0.4228, validation_loss:0.4253, val_accuracy:0.8312\n",
      "Epoch [161/200], average_loss:0.4245, validation_loss:0.4253, val_accuracy:0.8182\n",
      "Epoch [162/200], average_loss:0.4236, validation_loss:0.4276, val_accuracy:0.7792\n",
      "Epoch [163/200], average_loss:0.4248, validation_loss:0.4293, val_accuracy:0.7922\n",
      "Epoch [164/200], average_loss:0.4250, validation_loss:0.4283, val_accuracy:0.8182\n",
      "Epoch [165/200], average_loss:0.4232, validation_loss:0.4285, val_accuracy:0.8182\n",
      "Epoch [166/200], average_loss:0.4233, validation_loss:0.4316, val_accuracy:0.7922\n",
      "Epoch [167/200], average_loss:0.4236, validation_loss:0.4293, val_accuracy:0.8701\n",
      "Epoch [168/200], average_loss:0.4230, validation_loss:0.4297, val_accuracy:0.8182\n",
      "Epoch [169/200], average_loss:0.4224, validation_loss:0.4244, val_accuracy:0.8961\n",
      "Epoch [170/200], average_loss:0.4247, validation_loss:0.4271, val_accuracy:0.8182\n",
      "Epoch [171/200], average_loss:0.4226, validation_loss:0.4317, val_accuracy:0.7922\n",
      "Epoch [172/200], average_loss:0.4233, validation_loss:0.4272, val_accuracy:0.8182\n",
      "Epoch [173/200], average_loss:0.4233, validation_loss:0.4294, val_accuracy:0.8182\n",
      "Epoch [174/200], average_loss:0.4227, validation_loss:0.4285, val_accuracy:0.7662\n",
      "Epoch [175/200], average_loss:0.4236, validation_loss:0.4287, val_accuracy:0.8182\n",
      "Epoch [176/200], average_loss:0.4233, validation_loss:0.4302, val_accuracy:0.8182\n",
      "Epoch [177/200], average_loss:0.4229, validation_loss:0.4292, val_accuracy:0.7922\n",
      "Epoch [178/200], average_loss:0.4227, validation_loss:0.4273, val_accuracy:0.8312\n",
      "Epoch [179/200], average_loss:0.4226, validation_loss:0.4337, val_accuracy:0.7532\n",
      "Epoch [180/200], average_loss:0.4245, validation_loss:0.4311, val_accuracy:0.7532\n",
      "Epoch [181/200], average_loss:0.4236, validation_loss:0.4327, val_accuracy:0.7273\n",
      "Epoch [182/200], average_loss:0.4225, validation_loss:0.4306, val_accuracy:0.7662\n",
      "Epoch [183/200], average_loss:0.4231, validation_loss:0.4292, val_accuracy:0.8052\n",
      "Epoch [184/200], average_loss:0.4245, validation_loss:0.4319, val_accuracy:0.6883\n",
      "Epoch [185/200], average_loss:0.4224, validation_loss:0.4246, val_accuracy:0.8442\n",
      "Epoch [186/200], average_loss:0.4234, validation_loss:0.4282, val_accuracy:0.8312\n",
      "Epoch [187/200], average_loss:0.4227, validation_loss:0.4230, val_accuracy:0.8701\n",
      "Epoch [188/200], average_loss:0.4232, validation_loss:0.4268, val_accuracy:0.8312\n",
      "Epoch [189/200], average_loss:0.4241, validation_loss:0.4262, val_accuracy:0.8701\n",
      "Epoch [190/200], average_loss:0.4230, validation_loss:0.4304, val_accuracy:0.7792\n",
      "Epoch [191/200], average_loss:0.4228, validation_loss:0.4287, val_accuracy:0.7532\n",
      "Epoch [192/200], average_loss:0.4224, validation_loss:0.4290, val_accuracy:0.8312\n",
      "Epoch [193/200], average_loss:0.4230, validation_loss:0.4300, val_accuracy:0.8571\n",
      "Epoch [194/200], average_loss:0.4224, validation_loss:0.4262, val_accuracy:0.8052\n",
      "Epoch [195/200], average_loss:0.4229, validation_loss:0.4309, val_accuracy:0.7792\n",
      "Epoch [196/200], average_loss:0.4221, validation_loss:0.4317, val_accuracy:0.7662\n",
      "Epoch [197/200], average_loss:0.4239, validation_loss:0.4324, val_accuracy:0.7532\n",
      "Epoch [198/200], average_loss:0.4210, validation_loss:0.4301, val_accuracy:0.7792\n",
      "Epoch [199/200], average_loss:0.4217, validation_loss:0.4276, val_accuracy:0.8052\n",
      "Epoch [200/200], average_loss:0.4243, validation_loss:0.4322, val_accuracy:0.7662\n"
     ]
    }
   ],
   "source": [
    "lh = m2(epochs=range(100,200), train_loader=train_loader, validation_loader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dl-v7vuW7ZGJ"
   },
   "outputs": [],
   "source": [
    "#m2.tb.close()\n",
    "m2.model.eval()\n",
    "with torch.no_grad():\n",
    "    x_pred = np.argmax(m2.model.clf(torch.tensor(X_test).float().to(m2.device)).cpu().detach(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nVJcVBba7ZQj",
    "outputId": "ad9c9adf-e291-4a61-a997-f61280318e43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.641180326377472"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true=y_test, y_pred=x_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UpfUu-pxOFiW",
    "outputId": "93e7f8c2-3088-4f86-fd14-ba7e644eb74d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6717853728489483"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "TBNwia05OFl4",
    "outputId": "bcfd8546-69ad-44f6-8f01-f3451a830d2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1833, 1481,   82,  839],\n",
       "       [2044, 7565,  130,  706],\n",
       "       [  11,    4,  391,   73],\n",
       "       [  69,   46,    8, 1454]], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true=y_test, y_pred=x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(m2.model.clf, \"models_and_losses/DeepLSTM_VAE_NLL_440ep_hidden-128_lr-{1e-3, 1e-4}_bs-300+DNN_(drop)_on_VAE_sampling_latent_space_m.VI_lr-{1e-2,1e-3}_bs-512_epoch-200.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Classification on CNN-VAE latent space with NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
